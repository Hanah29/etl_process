{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aecc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aaa\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.11-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\aaa\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aaa\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aaa\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aaa\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aaa\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aaa\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading psycopg2_binary-2.9.11-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.8/2.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.11\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas psycopg2-binary python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ca701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Step 1. Setup and Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Step 2. Load Environment Variables\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database settings\n",
    "DB_NAME = os.getenv(\"PG_DBNAME\")\n",
    "DB_USER = os.getenv(\"PG_USER\")\n",
    "DB_PASSWORD = os.getenv(\"PG_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"PG_HOST\")\n",
    "DB_PORT = os.getenv(\"PG_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# File settings\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\")\n",
    "CHUNK_SIZE = int(os.getenv(\"CHUNK_SIZE\", \"200000\"))\n",
    "TABLE_NAME = os.getenv(\"TABLE_NAME\", \"people\")\n",
    "\n",
    "print(\" Environment variables loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15393e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Step 3. Define Database Table Schema\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "    row_index INTEGER,\n",
    "    user_id VARCHAR(50),\n",
    "    first_name TEXT,\n",
    "    last_name TEXT,\n",
    "    sex VARCHAR(10),\n",
    "    email TEXT,\n",
    "    phone TEXT,\n",
    "    date_of_birth DATE,\n",
    "    job_title TEXT\n",
    ");\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c94cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Step 4. Define ETL Functions\n",
    "\n",
    "def extract_csv(csv_path, chunk_size):\n",
    "    \"\"\"Extracts data from a large CSV file in chunks.\"\"\"\n",
    "    print(f\"Extracting data from: {csv_path}\")\n",
    "    return pd.read_csv(csv_path, chunksize=chunk_size, dtype=str, na_values=[\"\", \"NA\", \"N/A\"])\n",
    "\n",
    "\n",
    "def transform_chunk(chunk):\n",
    "    \"\"\"Cleans and transforms a single chunk of data.\"\"\"\n",
    "    column_map = {\n",
    "        \"Index\": \"row_index\",\n",
    "        \"User Id\": \"user_id\",\n",
    "        \"First Name\": \"first_name\",\n",
    "        \"Last Name\": \"last_name\",\n",
    "        \"Sex\": \"sex\",\n",
    "        \"Email\": \"email\",\n",
    "        \"Phone\": \"phone\",\n",
    "        \"Date of birth\": \"date_of_birth\",\n",
    "        \"Job Title\": \"job_title\"\n",
    "    }\n",
    "\n",
    "    # Rename columns\n",
    "    chunk.rename(columns=column_map, inplace=True)\n",
    "\n",
    "    # Convert date format\n",
    "    if \"date_of_birth\" in chunk.columns:\n",
    "        chunk[\"date_of_birth\"] = pd.to_datetime(chunk[\"date_of_birth\"], errors=\"coerce\")\n",
    "\n",
    "    # Fill missing values\n",
    "    chunk.fillna({\"first_name\": \"Unknown\", \"last_name\": \"Unknown\", \"job_title\": \"Unspecified\"}, inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    expected_columns = [\n",
    "        \"row_index\", \"user_id\", \"first_name\", \"last_name\",\n",
    "        \"sex\", \"email\", \"phone\", \"date_of_birth\", \"job_title\"\n",
    "    ]\n",
    "    chunk = chunk[[col for col in expected_columns if col in chunk.columns]]\n",
    "\n",
    "    print(f\" Transformed chunk with {len(chunk)} rows\")\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def copy_from_stringio(conn, df, table):\n",
    "    \"\"\"Efficiently loads a Pandas DataFrame into PostgreSQL using COPY.\"\"\"\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False)\n",
    "    buffer.seek(0)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(buffer, table, sep=\",\", null=\"\")\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(\" Error during COPY:\", e)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "def load_to_postgres(conn, chunk, table_name):\n",
    "    \"\"\"Loads one chunk of data into PostgreSQL.\"\"\"\n",
    "    copy_from_stringio(conn, chunk, table_name)\n",
    "    print(f\" Loaded {len(chunk)} records into '{table_name}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
